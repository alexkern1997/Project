{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\project\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on the articles\n",
    "This notebook implements a naive sentiment analysis on our dataset. Naive sentiment analysis employs the dictionary method to assign a sentiment to each word. By using the Sentiwordnet, it not only takes into account the actual word but also the word meaning. The cell below loads in our article dataset and also corrects the type of certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json('articles.json')\n",
    "articles.publicationDay = pd.to_datetime(articles.publicationDay, unit='ms')\n",
    "articles.publicationWeek = pd.to_datetime(articles.publicationWeek, unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create a set of english stopwords and also a list of punctuation symbols. These combined list of words will be entirely ignored when calculating polarities. Each word will be ignored when using this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'December', '2019', 'Dear', 'Boris', 'Johnson', 'In', 'medicine', '–', 'unlike', 'politics', 'anything', 'seems', 'go', 'days', '–', 'situations', 'called', '“', 'never', 'events', '”', 'These', 'instances', 'occur', 'patient', 'seriously', 'harmed', 'spite', 'protocols', 'protective', 'measures', 'prevent', 'happening', '“', 'Never', 'events', '”', 'serious', 'manmade', 'disasters', 'clinicians', 'involved', 'bear', 'burden', 'tragic', 'events', 'rest', 'careers', 'Like', 'many', 'junior', 'doctors', 'worked', 'overwhelmed', 'understaffed', 'A', 'amp', 'E', 'departments', 'I', '’', 'seen', 'things', 'happen', 'result', 'overstretched', 'conditions', 'I', 'believe', 'classed', '“', 'never', 'events', '”', 'Since', '2016', 'nearly', '5,500', 'patients', 'died', 'England', 'alone', 'direct', 'result', 'waited', 'long', 'admitted', 'hospital', 'To', 'put', 'perspective', '’', 'nearly', 'twice', 'number', 'people', 'killed', 'terror', 'attacks', 'UK', 'since', '1970', 'We', 'outraged', 'Prime', 'Minister', 'please', 'try', 'imagine', 'one', 'moment', 'working', 'NHS', 'paramedic', 'doctor', 'nurse', 'conditions', 'overstretched', 'ambulances', 'endure', 'dangerous', 'queues', 'see', 'patients', 'die', 'corridor', 'trolleys', 'result', 'Just', 'stop', 'moment', '–', 'please', '–', 'think', 'human', 'consequences', 'NHS', 'underfunding', 'The', 'NHS', 'everywhere', 'desperately', 'underfunded', 'understaffed', '–', 'party', 'government', 'Your', 'refusal', 'correct', 'systemic', 'problems', 'created', '5,000', '“', 'never', 'events', '”', 'Prime', 'Minister', 'failed', 'patients', 'negligence', 'contributed', 'deaths', 'You', 'party', 'nearly', 'decade', 'leave', 'health', 'service', 'better', 'state', 'found', 'On', 'every', 'objective', 'metric', 'Conservative', 'party', 'failed', 'see', 'NHS', 'hospitals', 'every', 'single', 'day', 'England', 'short', '40,000', 'nurses', '10,000', 'doctors', 'A', 'amp', 'E', 'waiting', 'times', 'absolute', 'worst', 'NHS', 'history', 'cancer', 'patients', 'waiting', 'longer', 'ever', 'seen', 'shut', 'many', 'district', 'hospitals', 'left', 'us', 'hospital', 'beds', 'social', 'care', 'mess', 'mental', 'health', 'care', 'inaccessible', 'destroyed', 'capacity', 'provide', 'multitude', 'services', 'community', 'keep', 'people', 'healthy', 'hospital', 'And', 'nearly', '5,500', 'people', 'died', 'direct', 'result', 'policies', 'This', 'legacy', '“', 'one', 'nation', '”', 'Conservative', 'party', 'If', 'care', 'fixing', 'stop', 'coming', 'hospitals', 'surreptitious', 'unannounced', 'photo', 'opportunities', '’', 'scared', 'us', 'asking', 'tough', 'questions', '–', 'start', 'listening', 'medical', 'experts', 'instead', 'We', '’', 'need', 'privatisation', 'American', 'companies', 'We', '’', 'need', 'expensive', 'consultants', 'middle', 'management', 'getting', 'involved', 'We', 'need', 'listen', 'Dr', 'Katherine', 'Henderson', 'president', 'Royal', 'College', 'Emergency', 'Medicine', 'says', '“', 'Patients', 'let', 'repeatedly', 'parliament', 'consistently', 'failed', 'grasp', 'scale', 'problem', '…', 'Our', 'staff', 'stretched', 'beyond', 'limits', '…', 'At', 'simplest', 'need', 'beds', 'need', 'staff', 'need', 'social', 'care', 'Politicians', 'must', 'make', 'happen.', '”', 'When', '“', 'never', 'event', '”', 'occurs', 'hospital', 'clinicians', 'involved', 'often', 'subject', 'lengthy', 'investigations', 'serious', 'consequences', 'meted', 'sometimes', 'include', 'losing', 'licence', 'practise', 'medicine', 'After', 'nine', 'years', 'gross', 'negligence', 'nine', 'years', 'lecturing', 'British', 'people', '“', 'one', 'nation', '”', 'Conservative', 'party', 'choice', 'make', 'NHS', 'safer', 'efficient', 'productive', '’', 'seen', 'Tory', 'governments', 'accomplished', 'worst', 'A', 'amp', 'E', 'waiting', 'times', 'NHS', 'history', 'people', 'dying', 'corridors', 'fifth', 'richest', 'country', 'Earth', 'You', 'fit', 'lecture', 'us', 'need', 'NHS', 'hospitals', 'You', 'failed', 'British', 'people', 'failed', 'beloved', 'Worcestershire', 'Royal', 'hospital', 'failed', 'brilliant', 'hardworking', 'NHS', 'staff', 'nationwide', 'traumatised', 'negligence', 'Because', 'safety', 'patients', 'threatened', 'significant', 'degree', 'I', 'exercising', 'right', 'whistleblower', 'clause', '29', 'contract', 'speak', '–', 'outside', 'sanctioned', 'channels', '–', 'happened', 'many', 'times', 'hospitals', 'across', 'country', 'British', 'public', 'right', 'know', 'exactly', 'responsible', 'Prime', 'Minister', 'NHS', 'safe', 'hands', 'Your', 'negligence', 'party', 'past', 'decade', 'contributed', 'deaths', 'nearly', '5,500', 'patients', 'junior', 'doctor', 'like', 'licence', 'would', 'revoked', 'would', 'sent', 'prison', '•', 'Andrew', 'Meyerson', 'junior', 'doctor', 'working', 'Worcestershire', 'Royal', 'hospital', 'His', 'views', 'represent', 'speak', 'NHS', 'England', 'Worcestershire', 'Royal', 'Hospital']\n"
     ]
    }
   ],
   "source": [
    "def remove_words(article):\n",
    "    article = word_tokenize(article)\n",
    "    return [word for word in article if not word in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create a function which we can give the text of an article. This function will look at each word in article. Each word will get a sentiment-score `weight` for each different meaning of the word in the dictonary. These weights are then averaged and added to the total article polarity `articlePolarity` which represents the cumulative averaged sentiment score of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveSentiment(article):\n",
    "    articlePolarity = 0\n",
    "    numExceptions = 0\n",
    "    for word in article:\n",
    "        word = word.lower()\n",
    "        numMeanings = 0\n",
    "        weight = 0.0\n",
    "        try:\n",
    "            for meaning in swn.senti_synsets(word):\n",
    "                if meaning.pos_score() > meaning.neg_score():\n",
    "                    weight += (meaning.pos_score() - meaning.neg_score())\n",
    "                    numMeanings += 1\n",
    "                elif meaning.pos_score() < meaning.neg_score():\n",
    "                    weight -= (meaning.neg_score() - meaning.pos_score())\n",
    "                    numMeanings += 1\n",
    "        except:\n",
    "            numExceptions += 1\n",
    "        if numMeanings > 0:\n",
    "            articlePolarity += (weight/numMeanings)\n",
    "    return articlePolarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'December', '2019', 'Dear', 'Boris', 'Johnson', 'In', 'medicine', '–', 'unlike', 'politics', 'anything', 'seems', 'go', 'days', '–', 'situations', 'called', '“', 'never', 'events', '”', 'These', 'instances', 'occur', 'patient', 'seriously', 'harmed', 'spite', 'protocols', 'protective', 'measures', 'prevent', 'happening', '“', 'Never', 'events', '”', 'serious', 'manmade', 'disasters', 'clinicians', 'involved', 'bear', 'burden', 'tragic', 'events', 'rest', 'careers', 'Like', 'many', 'junior', 'doctors', 'worked', 'overwhelmed', 'understaffed', 'A', 'amp', 'E', 'departments', 'I', '’', 'seen', 'things', 'happen', 'result', 'overstretched', 'conditions', 'I', 'believe', 'classed', '“', 'never', 'events', '”', 'Since', '2016', 'nearly', '5,500', 'patients', 'died', 'England', 'alone', 'direct', 'result', 'waited', 'long', 'admitted', 'hospital', 'To', 'put', 'perspective', '’', 'nearly', 'twice', 'number', 'people', 'killed', 'terror', 'attacks', 'UK', 'since', '1970', 'We', 'outraged', 'Prime', 'Minister', 'please', 'try', 'imagine', 'one', 'moment', 'working', 'NHS', 'paramedic', 'doctor', 'nurse', 'conditions', 'overstretched', 'ambulances', 'endure', 'dangerous', 'queues', 'see', 'patients', 'die', 'corridor', 'trolleys', 'result', 'Just', 'stop', 'moment', '–', 'please', '–', 'think', 'human', 'consequences', 'NHS', 'underfunding', 'The', 'NHS', 'everywhere', 'desperately', 'underfunded', 'understaffed', '–', 'party', 'government', 'Your', 'refusal', 'correct', 'systemic', 'problems', 'created', '5,000', '“', 'never', 'events', '”', 'Prime', 'Minister', 'failed', 'patients', 'negligence', 'contributed', 'deaths', 'You', 'party', 'nearly', 'decade', 'leave', 'health', 'service', 'better', 'state', 'found', 'On', 'every', 'objective', 'metric', 'Conservative', 'party', 'failed', 'see', 'NHS', 'hospitals', 'every', 'single', 'day', 'England', 'short', '40,000', 'nurses', '10,000', 'doctors', 'A', 'amp', 'E', 'waiting', 'times', 'absolute', 'worst', 'NHS', 'history', 'cancer', 'patients', 'waiting', 'longer', 'ever', 'seen', 'shut', 'many', 'district', 'hospitals', 'left', 'us', 'hospital', 'beds', 'social', 'care', 'mess', 'mental', 'health', 'care', 'inaccessible', 'destroyed', 'capacity', 'provide', 'multitude', 'services', 'community', 'keep', 'people', 'healthy', 'hospital', 'And', 'nearly', '5,500', 'people', 'died', 'direct', 'result', 'policies', 'This', 'legacy', '“', 'one', 'nation', '”', 'Conservative', 'party', 'If', 'care', 'fixing', 'stop', 'coming', 'hospitals', 'surreptitious', 'unannounced', 'photo', 'opportunities', '’', 'scared', 'us', 'asking', 'tough', 'questions', '–', 'start', 'listening', 'medical', 'experts', 'instead', 'We', '’', 'need', 'privatisation', 'American', 'companies', 'We', '’', 'need', 'expensive', 'consultants', 'middle', 'management', 'getting', 'involved', 'We', 'need', 'listen', 'Dr', 'Katherine', 'Henderson', 'president', 'Royal', 'College', 'Emergency', 'Medicine', 'says', '“', 'Patients', 'let', 'repeatedly', 'parliament', 'consistently', 'failed', 'grasp', 'scale', 'problem', '…', 'Our', 'staff', 'stretched', 'beyond', 'limits', '…', 'At', 'simplest', 'need', 'beds', 'need', 'staff', 'need', 'social', 'care', 'Politicians', 'must', 'make', 'happen.', '”', 'When', '“', 'never', 'event', '”', 'occurs', 'hospital', 'clinicians', 'involved', 'often', 'subject', 'lengthy', 'investigations', 'serious', 'consequences', 'meted', 'sometimes', 'include', 'losing', 'licence', 'practise', 'medicine', 'After', 'nine', 'years', 'gross', 'negligence', 'nine', 'years', 'lecturing', 'British', 'people', '“', 'one', 'nation', '”', 'Conservative', 'party', 'choice', 'make', 'NHS', 'safer', 'efficient', 'productive', '’', 'seen', 'Tory', 'governments', 'accomplished', 'worst', 'A', 'amp', 'E', 'waiting', 'times', 'NHS', 'history', 'people', 'dying', 'corridors', 'fifth', 'richest', 'country', 'Earth', 'You', 'fit', 'lecture', 'us', 'need', 'NHS', 'hospitals', 'You', 'failed', 'British', 'people', 'failed', 'beloved', 'Worcestershire', 'Royal', 'hospital', 'failed', 'brilliant', 'hardworking', 'NHS', 'staff', 'nationwide', 'traumatised', 'negligence', 'Because', 'safety', 'patients', 'threatened', 'significant', 'degree', 'I', 'exercising', 'right', 'whistleblower', 'clause', '29', 'contract', 'speak', '–', 'outside', 'sanctioned', 'channels', '–', 'happened', 'many', 'times', 'hospitals', 'across', 'country', 'British', 'public', 'right', 'know', 'exactly', 'responsible', 'Prime', 'Minister', 'NHS', 'safe', 'hands', 'Your', 'negligence', 'party', 'past', 'decade', 'contributed', 'deaths', 'nearly', '5,500', 'patients', 'junior', 'doctor', 'like', 'licence', 'would', 'revoked', 'would', 'sent', 'prison', '•', 'Andrew', 'Meyerson', 'junior', 'doctor', 'working', 'Worcestershire', 'Royal', 'hospital', 'His', 'views', 'represent', 'speak', 'NHS', 'England', 'Worcestershire', 'Royal', 'Hospital']\n",
      "0.0654158215010142\n"
     ]
    }
   ],
   "source": [
    "print(remove_words(articles.bodyText[0]))\n",
    "x = []\n",
    "for word in remove_words(articles.bodyText[0]):\n",
    "    x.append(naiveSentiment(word))\n",
    "print(sum(x)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7880/7880 [01:24<00:00, 93.57it/s]\n"
     ]
    }
   ],
   "source": [
    "articles['filteredbodyText'] = articles.bodyText.progress_apply(remove_words)\n",
    "articles['filteredwordcount'] = articles.filteredbodyText.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7880/7880 [07:14<00:00, 18.14it/s]\n"
     ]
    }
   ],
   "source": [
    "articles['articlePolarity'] = articles.filteredbodyText.progress_apply(naiveSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7880.000000\n",
       "mean       14.416065\n",
       "std        26.769659\n",
       "min       -27.378959\n",
       "25%         5.222044\n",
       "50%        10.119936\n",
       "75%        16.333662\n",
       "max       582.724918\n",
       "Name: articlePolarity, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.articlePolarity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['articlePolarityNormalized'] = articles.articlePolarity / articles.filteredwordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7880.000000\n",
       "mean        0.024709\n",
       "std         0.016693\n",
       "min        -0.055556\n",
       "25%         0.013772\n",
       "50%         0.024361\n",
       "75%         0.035184\n",
       "max         0.105938\n",
       "Name: articlePolarityNormalized, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.articlePolarityNormalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = articles.groupby('publicationDay').articlePolarity.mean()\n",
    "plt.plot(resp)\n",
    "plt.title('Average sentiment score per Day')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = articles.groupby('publicationWeek').articlePolarity.mean()\n",
    "plt.plot(resp)\n",
    "plt.title('Average sentiment score per Week')\n",
    "plt.xlabel('Weeks')\n",
    "plt.ylabel('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.to_json('articles_sentiment.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
